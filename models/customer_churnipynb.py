# -*- coding: utf-8 -*-
"""Customer_Churnipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1trc4MXYfQXxhmN0aGuu_VFlE_2pTBToW
"""

#Importing Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import joblib

# Load dataset
df = pd.read_csv("dataset.csv")

df.head()

df.tail()

#Check the size of the dataset (rows, columns)
print(df.shape)

# All column names
df.columns

# Data types of each column
print(df.dtypes)

# Count how many missing (NaN) values are in each column
print(df.isna().sum())

"""There is no any null values"""

#Drop Unnecessary Column
df = df.copy()
if 'customerID' in df.columns:
    df.drop('customerID', axis=1, inplace=True)

"""**EDA**"""

df.columns

#Numerical columns
df_num = df.select_dtypes(exclude=['bool_', 'object_'])
df_num.head(2)

# Categorical columns
df_cat = df.select_dtypes(include=['object'])
df_cat.head(2)

# Drop SeniorCitizen to get correlation
df_num_n = df_num.drop(['SeniorCitizen'], axis=1)

## corelation between numerical variables
correlation_matrix = df_num_n.corr()
print(correlation_matrix)

"""**1.tenure vs TotalCharges: 0.804**

Strong positive correlation.
The longer a customer has been with the company (tenure), the higher their TotalCharges will be (more months billed).

**2.MonthlyCharges vs TotalCharges: 0.603**

Moderate positive correlation.
Higher monthly charges usually result in higher total charges over time.

**3.tenure vs MonthlyCharges: 0.12**

Very weak positive correlation
Tenure and monthly charges are mostly independent — long-term customers don’t necessarily pay higher monthly charges.

"""

## Create histogram for numerical data
df_num_n.hist()

sns.set(style="whitegrid")

# Boxplot for TotalCharges
plt.figure(figsize=(12, 6))
sns.boxplot(x='TotalCharges', data=df)
plt.title('Boxplot of TotalCharges', fontsize=16)
plt.xlabel('TotalCharges', fontsize=12)
plt.show()

# Boxplot for MonthlyCharges
plt.figure(figsize=(12, 6))
sns.boxplot(x='MonthlyCharges', data=df)
plt.title('Boxplot of MonthlyCharges', fontsize=16)
plt.xlabel('MonthlyCharges', fontsize=12)
plt.show()

# Boxplot for tenure
plt.figure(figsize=(12, 6))
sns.boxplot(x='tenure', data=df)
plt.title('Boxplot of Tenure', fontsize=16)
plt.xlabel('Tenure (Months)', fontsize=12)
plt.show()

# Plotting categorical data

f = pd.melt(df, value_vars=sorted(df_cat))
g = sns.FacetGrid(f, col='variable', col_wrap=4, sharex=False, sharey=False, height=4, aspect=1.2)


plt.xticks(rotation=60)
g.map(sns.countplot, 'value', order=None)
[plt.setp(ax.get_xticklabels(), rotation=60) for ax in g.axes.flat]

g.fig.tight_layout()

plt.show()

#number of unique values in each column
df.nunique()

label_encorder = LabelEncoder()

# Encode categorical features
label_encoders = {}
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = label_encorder.fit_transform(df[col])
        label_encoders[col] = label_encorder

df.head()

# Define the target column
X = df.drop(['Churn'], axis=1)
y = df['Churn']

X.shape, y.shape

from sklearn.preprocessing import StandardScaler

#Feature Scaling
scaler = StandardScaler()

X = scaler.fit_transform(X)

X = pd.DataFrame(X)

X.head(2)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the train, validation, and test sets to verify the split
print("Shapes:", X_train.shape, X_val.shape, X_test.shape)

"""**Model building**"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import xgboost as xgb
from sklearn.model_selection import cross_val_score

# Defining the classification models
models = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "AdaBoost": AdaBoostClassifier(),
    "Support Vector Machine": SVC(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Naive Bayes": GaussianNB(),
    "XGBoost": xgb.XGBClassifier()
}

# Dictionary to store accuracy scores and CV scores
model_accuracies = {}
model_cv_scores = {}

# Train, evaluate models, and perform cross-validation
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Dictionaries to store results
accuracy_results = {}
cv_mean_results = {}

for model_name, clf in models.items():
    # Predict on test set
    predictions = clf.predict(X_test)

    # Compute and store accuracy
    acc = accuracy_score(y_test, predictions)
    accuracy_results[model_name] = acc

    # Print model evaluation
    print(f"=== {model_name} Evaluation ===")
    print(f"Test Accuracy : {acc:.4f}")
    print("Detailed Classification Report:")
    print(classification_report(y_test, predictions))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, predictions))
    print("="*60)

    # Perform 5-fold cross-validation on training data
    cv_scores = cross_val_score(clf, X_train, y_train, cv=5)
    cv_mean = cv_scores.mean()
    cv_mean_results[model_name] = cv_mean

    print(f"5-Fold CV Scores for {model_name}: {cv_scores}")
    print(f"Average CV Score: {cv_mean:.4f}")
    print("="*60)

# Print a summary table of all model accuracies
print("\n=== Model Accuracy Overview ===")
for model, acc in accuracy_results.items():
    print(f"{model:<20} -> {acc:.3f}")

print("\n=== Model Cross-Validation Averages ===")
for model, cv_avg in cv_mean_results.items():
    print(f"{model:<20} -> {cv_avg:.3f}")

## Identify top-performing model using cross-validation averages
optimal_model = max(cv_mean_results, key=cv_mean_results.get)
optimal_cv = cv_mean_results[optimal_model]

print("\n=== Best Performing Model ===")
print(f"Model Selected : {optimal_model}")
print(f"Mean CV Score  : {optimal_cv:.3f}")

# Save the highest-performing model
final_model = models[optimal_model]

final_model

import pickle
# Save models
with open('final_model.pkl', 'wb') as f:
    pickle.dump(final_model, f)


with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

with open('label_encoders.pkl', 'wb') as f:
    pickle.dump(label_encoders, f)

"""**Inferencing**"""

df.head()

user_input = {
    "gender": "Female",
    "SeniorCitizen": 1,
    "Partner": "Yes",
    "Dependents": "Yes",
    "tenure": 21,
    "PhoneService": "Yes",
    "MultipleLines": "Yes",
    "InternetService": "DSL",
    "OnlineSecurity": "Yes",
    "OnlineBackup": "No",
    "DeviceProtection": "No internet service",
    "TechSupport": "No",
    "StreamingTV": "No",
    "StreamingMovies": "No internet service",
    "Contract": "One year",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Bank transfer",
    "MonthlyCharges": 18.64,
    "TotalCharges": 430.2
}

with open('/content/final_model.pkl', 'rb') as f:
    best_model = pickle.load(f)

with open('/content/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

with open('/content/label_encoders.pkl', 'rb') as f:
    label_encoders = pickle.load(f)

def predict_churn(user_input):
    # Convert user input to DataFrame
    user_input_df = pd.DataFrame([user_input])

    # Encode categorical features
    for col, encoder in label_encoders.items():
        if col in user_input_df.columns:
            # Check if the label encoder has seen the category
            known_categories = set(encoder.classes_)
            new_categories = set(user_input_df[col].unique())
            unseen_categories = new_categories - known_categories

            if unseen_categories:
                # Map unseen categories to a default value (e.g., the most frequent category or a special category)
                default_value = encoder.classes_[0]
                user_input_df[col] = user_input_df[col].apply(lambda x: x if x in known_categories else default_value)

            user_input_df[col] = encoder.transform(user_input_df[col])

    # Normalize data
    user_input_scaled = scaler.transform(user_input_df)

    # Predict churn
    user_churn_prediction = best_model.predict(user_input_scaled)

    # Check if the best model supports predict_proba
    if hasattr(best_model, "predict_proba"):
        user_churn_prediction_proba = best_model.predict_proba(user_input_scaled)
        return user_churn_prediction[0], user_churn_prediction_proba[0]
    else:
        return user_churn_prediction[0], None

churn_prediction, churn_prediction_proba = predict_churn(user_input)
print("User Churn Prediction (0: No, 1: Yes):", churn_prediction)
if churn_prediction_proba is not None:
    print("User Churn Prediction Probability:", churn_prediction_proba)
else:
  pass
    #print("Probability estimation is not supported for the selected model:", best_model_name)